{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8ee9359-5bc3-439f-8aa9-bcb4832edda3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import io\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Owlv2ForObjectDetection\n",
    "import numpy as np\n",
    "\n",
    "class VLMManager:\n",
    "    def __init__(self):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.processor = AutoProcessor.from_pretrained(\"google/owlv2-base-patch16-ensemble\")\n",
    "        self.model = Owlv2ForObjectDetection.from_pretrained(\"google/owlv2-base-patch16-ensemble\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def resize(self, img, base_width=380):\n",
    "        wpercent = (base_width / float(img.size[0]))\n",
    "        hsize = int((float(img.size[1]) * float(wpercent)))\n",
    "        img = img.resize((base_width, hsize), Image.Resampling.LANCZOS)\n",
    "        return img\n",
    "\n",
    "    def resize_box(self, box, original_size, resized_size):\n",
    "        x_scale = original_size[0] / resized_size[0]\n",
    "        y_scale = original_size[1] / resized_size[1]\n",
    "        resized_box = [\n",
    "            box[0] * x_scale,\n",
    "            box[1] * y_scale,\n",
    "            box[2] * x_scale - box[0] * x_scale,\n",
    "            box[3] * y_scale - box[1] * y_scale\n",
    "        ]\n",
    "        return [int(round(coord, 0)) for coord in resized_box]\n",
    "\n",
    "    def identify(self, image: bytes, caption: str) -> List[int]:\n",
    "        image_stream = io.BytesIO(image)\n",
    "        image = Image.open(image_stream).convert('RGB')\n",
    "        ori_size = image.size\n",
    "        resized_image = self.resize(image)\n",
    "        \n",
    "        text = [[\"a photo of \" + caption.lower()]]\n",
    "        \n",
    "        inputs = self.processor(images=resized_image, text=text, return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        \n",
    "        target_sizes = torch.Tensor([resized_image.size[::-1]])\n",
    "        results = self.processor.post_process_object_detection(\n",
    "            outputs=outputs, threshold=0.2, target_sizes=target_sizes\n",
    "        )\n",
    "\n",
    "        i = 0\n",
    "        boxes, scores, labels = results[i][\"boxes\"], results[i][\"scores\"], results[i][\"labels\"]\n",
    "        \n",
    "        x, y = ori_size\n",
    "        final, best_score = [int(0.25*x), int(0.25*y), int(0.75*x), int(0.75*y)], 0\n",
    "        for box, score, label in zip(boxes, scores, labels):\n",
    "            if score.item() > best_score:\n",
    "                resized_box = self.resize_box(box.tolist(), ori_size, resized_image.size)\n",
    "                final = resized_box\n",
    "                best_score = score.item()\n",
    "\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f03a4b16-f832-4e41-a91f-e26552bbafbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Box: [803, 320, 123, 36]\n"
     ]
    }
   ],
   "source": [
    "vlm_manager = VLMManager()\n",
    "\n",
    "\n",
    "\n",
    "with open('image_0.jpg', 'rb') as img_file:\n",
    "    image_bytes = img_file.read()\n",
    "caption = \"blue and white commercial aircraft\"\n",
    "bounding_box = vlm_manager.identify(image_bytes, caption)\n",
    "print(\"Bounding Box:\", bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff53c013-c465-4782-947c-57a0810cafb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from https://gist.github.com/meyerjo/dd3533edc97c81258898f60d8978eddc\n",
    "\n",
    "\n",
    "from statistics import mean\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def bb_iou(bb1: List[int], bb2: List[int]) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) of two bounding boxes in ltwh format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bb1 : list[int, int, int, int]\n",
    "        left, top, width, height\n",
    "    bb2 : list[int, int, int, int]\n",
    "        left, top, width, height\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        0 or 1\n",
    "    \"\"\"\n",
    "    boxA = [bb1[0], bb1[1], bb1[0] + bb1[2], bb1[1] + bb1[3]]\n",
    "    boxB = [bb2[0], bb2[1], bb2[0] + bb2[2], bb2[1] + bb2[3]]\n",
    "\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = abs(max((xB - xA, 0)) * max((yB - yA), 0))\n",
    "    if interArea == 0:\n",
    "        return 0.0\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = abs((boxA[2] - boxA[0]) * (boxA[3] - boxA[1]))\n",
    "    boxBArea = abs((boxB[2] - boxB[0]) * (boxB[3] - boxB[1]))\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value @ 0.5\n",
    "    return round(iou)\n",
    "\n",
    "\n",
    "def vlm_eval(bbox_truths: List[List[int]], bbox_predictions: List[List[int]]) -> float:\n",
    "    return mean(\n",
    "        bb_iou(bb_truth, bb_pred)\n",
    "        for bb_truth, bb_pred in zip(bbox_truths, bbox_predictions)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08d945d1-c456-4f6b-8bd7-bab19234e989",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = [{'key': 0, 'bbox': [380, 217, 760, 435]}, {'key': 1, 'bbox': [803, 320, 123, 36]}, {'key': 2, 'bbox': [803, 320, 123, 36]}, {'key': 3, 'bbox': [1301, 489, 121, 42]}, {'key': 4, 'bbox': [1301, 489, 121, 42]}, {'key': 5, 'bbox': [380, 217, 760, 435]}, {'key': 6, 'bbox': [380, 217, 760, 435]}, {'key': 7, 'bbox': [380, 217, 760, 435]}, {'key': 8, 'bbox': [211, 444, 71, 64]}, {'key': 9, 'bbox': [913, 152, 32, 20]}, {'key': 10, 'bbox': [539, 116, 67, 53]}, {'key': 11, 'bbox': [1106, 110, 54, 32]}, {'key': 12, 'bbox': [380, 217, 760, 435]}, {'key': 13, 'bbox': [380, 217, 760, 435]}, {'key': 14, 'bbox': [446, 175, 53, 25]}]\n",
    "truths = [{'key': 0, 'caption': 'blue and white missile', 'bbox': [1224, 284, 44, 36]}, {'key': 1, 'caption': 'green light aircraft', 'bbox': [688, 400, 56, 36]}, {'key': 2, 'caption': 'blue and white commercial aircraft', 'bbox': [800, 320, 128, 36]}, {'key': 3, 'caption': 'blue commercial aircraft', 'bbox': [1156, 496, 104, 60]}, {'key': 4, 'caption': 'white and yellow commercial aircraft', 'bbox': [1296, 488, 136, 44]}, {'key': 5, 'caption': 'white and blue fighter jet', 'bbox': [488, 196, 52, 44]}, {'key': 6, 'caption': 'blue and yellow fighter jet', 'bbox': [836, 464, 36, 36]}, {'key': 7, 'caption': 'grey and white fighter plane', 'bbox': [1060, 208, 64, 32]}, {'key': 8, 'caption': 'grey camouflage fighter jet', 'bbox': [212, 444, 72, 64]}, {'key': 9, 'caption': 'grey and black helicopter', 'bbox': [912, 144, 40, 28]}, {'key': 10, 'caption': 'grey commercial aircraft', 'bbox': [536, 116, 72, 52]}, {'key': 11, 'caption': 'red helicopter', 'bbox': [1100, 96, 60, 52]}, {'key': 12, 'caption': 'green and black camouflage helicopter', 'bbox': [1156, 268, 28, 32]}, {'key': 13, 'caption': 'grey and red fighter jet', 'bbox': [412, 352, 108, 56]}, {'key': 14, 'caption': 'black fighter plane', 'bbox': [448, 176, 52, 24]}]\n",
    "# results = [{'key': 0, 'bbox': [380, 217, 760, 435]}, {'key': 1, 'bbox': [803, 183, 123, 21]}, {'key': 2, 'bbox': [803, 183, 123, 21]}, {'key': 3, 'bbox': [1301, 279, 121, 24]}, {'key': 4, 'bbox': [1301, 279, 121, 24]}, {'key': 5, 'bbox': [380, 217, 760, 435]}, {'key': 6, 'bbox': [380, 217, 760, 435]}, {'key': 7, 'bbox': [380, 217, 760, 435]}, {'key': 8, 'bbox': [211, 253, 71, 37]}, {'key': 9, 'bbox': [913, 87, 32, 12]}, {'key': 10, 'bbox': [539, 66, 67, 31]}, {'key': 11, 'bbox': [1106, 63, 54, 18]}, {'key': 12, 'bbox': [380, 217, 760, 435]}, {'key': 13, 'bbox': [380, 217, 760, 435]}, {'key': 14, 'bbox': [446, 100, 53, 14]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dd223fe-55c8-4cac-bab6-3698a648747b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 1, 0.0, 1, 0, 0, 0, 1, 1, 1, 1, 0.0, 0, 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result = vlm_eval(\n",
    "        [truth[\"bbox\"] for truth in truths],\n",
    "        [result[\"bbox\"] for result in results],\n",
    "    )\n",
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ba5d1-8eb2-48c5-bae4-94ac16c2e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "green light aircraft tensor([200.7495,  45.5879, 231.4284,  50.7849]) tensor(0.4252) tensor(0)\n",
    "green light aircraft [803, 183, 123, 21]\n",
    "blue and white commercial aircraft tensor([200.7495,  45.5879, 231.4284,  50.7849]) tensor(0.3439) tensor(0)\n",
    "blue and white commercial aircraft [803, 183, 123, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8a0a54-6cf0-4704-8bfd-f60775b5d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "green light aircraft tensor([200.7495,  79.8314, 231.4284,  88.9321], device='cuda:0') tensor(0.4252, device='cuda:0') tensor(0, device='cuda:0')\n",
    "green light aircraft [803, 320, 123, 36]\n",
    "blue and white commercial aircraft tensor([200.7495,  79.8314, 231.4284,  88.9321], device='cuda:0') tensor(0.3439, device='cuda:0') tensor(0, device='cuda:0')\n",
    "blue and white commercial aircraft [803, 320, 123, 36]\n",
    "blue commercial aircraft tensor([297.9743, 124.1211, 303.7122, 137.8791], device='cuda:0') tensor(0.2218, device='cuda:0') tensor(0, device='cuda:0')\n",
    "blue commercial aircraft [1192, 498, 23, 55]\n",
    "blue commercial aircraft tensor([325.1395, 122.0269, 355.4868, 132.5076], device='cuda:0') tensor(0.2396, device='cuda:0') tensor(0, device='cuda:0')\n",
    "blue commercial aircraft [1301, 489, 121, 42]\n",
    "INFO:     127.0.0.1:53782 - \"POST /identify HTTP/1.1\" 200 OK\n",
    "white and yellow commercial aircraft tensor([325.1395, 122.0269, 355.4868, 132.5076], device='cuda:0') tensor(0.2629, device='cuda:0') tensor(0, device='cuda:0')\n",
    "white and yellow commercial aircraft [1301, 489, 121, 42]\n",
    "INFO:     127.0.0.1:53796 - \"POST /identify HTTP/1.1\" 200 OK\n",
    "grey camouflage fighter jet tensor([134.8471,  28.9070, 151.6177,  42.2461], device='cuda:0') tensor(0.4064, device='cuda:0') tensor(0, device='cuda:0')\n",
    "grey camouflage fighter jet [539, 116, 67, 53]\n",
    "grey camouflage fighter jet tensor([ 52.7718, 110.6222,  70.6236, 126.5716], device='cuda:0') tensor(0.4107, device='cuda:0') tensor(0, device='cuda:0')\n",
    "grey camouflage fighter jet [211, 444, 71, 64]\n",
    "grey and black helicopter tensor([228.1348,  37.7945, 236.2081,  42.8887], device='cuda:0') tensor(0.3743, device='cuda:0') tensor(0, device='cuda:0')\n",
    "grey and black helicopter [913, 152, 32, 20]\n",
    "grey commercial aircraft tensor([134.8471,  28.9070, 151.6177,  42.2461], device='cuda:0') tensor(0.5378, device='cuda:0') tensor(0, device='cuda:0')\n",
    "grey commercial aircraft [539, 116, 67, 53]\n",
    "red helicopter tensor([276.5785,  27.3723, 290.0326,  35.3073], device='cuda:0') tensor(0.4996, device='cuda:0') tensor(0, device='cuda:0')\n",
    "red helicopter [1106, 110, 54, 32]\n",
    "INFO:     127.0.0.1:42980 - \"POST /identify HTTP/1.1\" 200 OK\n",
    "black fighter plane tensor([111.5770,  43.7127, 124.8466,  49.9819], device='cuda:0') tensor(0.2040, device='cuda:0') tensor(0, device='cuda:0')\n",
    "black fighter plane [446, 175, 53, 25]\n",
    "INFO:     127.0.0.1:42992 - \"POST /identify HTTP/1.1\" 200 OK\n",
    "^CINFO:     Shutting down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d899e79c-b386-4d1c-8bb6-b13c4e0f145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import io\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Owlv2ForObjectDetection\n",
    "import numpy as np\n",
    "\n",
    "model = Owlv2ForObjectDetection.from_pretrained(\"google/owlv2-base-patch16-ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2237a0cf-1157-443e-9e3b-d19cc5955cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'locallysavedmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b83b51-749d-4c64-9cf9-6a97693f3e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
